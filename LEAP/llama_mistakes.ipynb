{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/math500/llama/math500_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append('../')  \n",
    "\n",
    "from math500.math_utils import *\n",
    "from math500.parser import *\n",
    "from math500.grader import *\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/math500/{model}/math500_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/math500/{model}/math500_wrong_predictions.jsonl\"\n",
    "\n",
    "    scores = [[] for _ in range(15)]\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "\n",
    "        for idx, entry in enumerate(data):\n",
    "\n",
    "            gt = extract_answer(entry['answer'], \"math\")\n",
    "            gt = strip_string(gt)\n",
    "\n",
    "            for i, mo in enumerate(entry['model_outputs']):\n",
    "\n",
    "                pred = extract_answer(mo, \"math\")\n",
    "                pred = strip_string(pred)\n",
    "\n",
    "                try:\n",
    "                    result = math_equal_process((idx, pred, gt))\n",
    "                    if not result:\n",
    "                        result = process_results(gt, [mo])\n",
    "\n",
    "                        if not result :\n",
    "                            wrong_entries.append({\n",
    "                                \"idx\": idx,\n",
    "                                \"entry\": entry,\n",
    "                                \"gt\": gt,\n",
    "                                \"model_index\": i,\n",
    "                                \"model_output\": mo,\n",
    "                                \"pred\": pred\n",
    "                            })\n",
    "                            break\n",
    "\n",
    "                    scores[i].append(result)\n",
    "\n",
    "                except TimeoutError:\n",
    "                    scores[i].append(False)\n",
    "                except Exception as error:\n",
    "                    print(f\"Error encountered: {error}\")\n",
    "                    exit()\n",
    "\n",
    "        if wrong_entries:\n",
    "            with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "                for we in wrong_entries:\n",
    "                    wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "            print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "        else:\n",
    "            print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehdtjr1220/miniconda3/envs/proj2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/mmlu_pro/llama/engineering/mmlu_pro_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from mmlu_pro.mmlu_utils import * \n",
    "\n",
    "def extract_answer(text):\n",
    "    pattern = r\"answer is \\(?([A-J])\\)?\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return extract_again(text)\n",
    "\n",
    "for model in ['llama']:\n",
    "    file_path = f\"../leap/mmlu_pro/{model}/mmlu_pro_mistakes.jsonl\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    \n",
    "\n",
    "    wrong_entries_by_subject = defaultdict(list)\n",
    "\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        subject = entry['subject']\n",
    "        gt = extract_answer(entry['answer'])\n",
    "        \n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = extract_answer(mo)\n",
    "            if pred != gt:\n",
    "                wrong_entries_by_subject[subject].append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "    \n",
    "\n",
    "    for subject, wrong_entries in wrong_entries_by_subject.items():\n",
    "        wrong_file_path = f\"../leap/mmlu_pro/{model}/{subject}/mmlu_pro_wrong_predictions.jsonl\"\n",
    "        os.makedirs(os.path.dirname(wrong_file_path), exist_ok=True)\n",
    "        \n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b1791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/gpqa/llama/gpqa_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "from gpqa.gpqa_utils import *\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/gpqa/{model}/gpqa_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/gpqa/{model}/gpqa_wrong_predictions.jsonl\"\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        gt = parse_sampled_answer(entry['answer'])\n",
    "\n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = parse_sampled_answer(mo)\n",
    "            if pred != gt: \n",
    "                wrong_entries.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if wrong_entries:\n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    else:\n",
    "        print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09cf5fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/hotpotqa/llama/hotpotqa_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "from hotpotqa.hotpotqa_utils import *\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/hotpotqa/{model}/hotpotqa_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/hotpotqa/{model}/hotpotqa_wrong_predictions.jsonl\"\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        gt = extract_answer(entry['answer'])\n",
    "        gt = normalize_answer(gt)\n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = extract_answer(mo)\n",
    "            pred = normalize_answer(pred)\n",
    "            if pred != gt: \n",
    "                wrong_entries.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if wrong_entries:\n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    else:\n",
    "        print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae1ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/drop/llama/drop_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "from drop.drop_utils import *\n",
    "from drop.drop_utils import _normalize\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/drop/{model}/drop_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/drop/{model}/drop_wrong_predictions.jsonl\"\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        gt = extract_answer(entry['answer'])\n",
    "\n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = extract_answer(mo)\n",
    "            pred = _normalize(pred)\n",
    "\n",
    "            em, _ = get_metrics(pred, gt)\n",
    "            if not em: \n",
    "                wrong_entries.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if wrong_entries:\n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    else:\n",
    "        print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5490ed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/musr_location/llama/musr_location_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "from musr.musr import MuSRDataset\n",
    "\n",
    "from musr.op_icl_fixed import op_fewshot, few_shot_op_instruction, test_op_instruction\n",
    "from musr.ta_icl_fixed import ta_fewshot, few_shot_ta_instruction, test_ta_instruction\n",
    "\n",
    "\n",
    "op_path = '../data/musr/object_placements.json'\n",
    "op = MuSRDataset(op_path)\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/musr_location/{model}/musr_location_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/musr_location/{model}/musr_location_wrong_predictions.jsonl\"\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        gt = op.evaluate_response([entry['answer']], op[0])[0]['model_answer']\n",
    "        \n",
    "\n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = op.evaluate_response([mo], op[0])[0]['model_answer']\n",
    "            \n",
    "            if pred != gt: \n",
    "                wrong_entries.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if wrong_entries:\n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    else:\n",
    "        print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fbf60c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved wrong predictions to ../leap/musr_efficiently/llama/musr_efficiently_wrong_predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "ta_path = '../data/musr/team_allocation.json'\n",
    "ta = MuSRDataset(ta_path)\n",
    "\n",
    "for model in ['llama']: \n",
    "    file_path = f\"../leap/musr_efficiently/{model}/musr_efficiently_mistakes.jsonl\"\n",
    "    wrong_file_path = f\"../leap/musr_efficiently/{model}/musr_efficiently_wrong_predictions.jsonl\"\n",
    "\n",
    "    wrong_entries = []  \n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    for idx, entry in enumerate(data):\n",
    "        gt = ta.evaluate_response([entry['answer']], ta[0])[0]['model_answer']\n",
    "        \n",
    "\n",
    "        for i, mo in enumerate(entry['model_outputs']):\n",
    "            pred = ta.evaluate_response([mo], ta[0])[0]['model_answer']\n",
    "            \n",
    "            if pred != gt: \n",
    "                wrong_entries.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"entry\": entry,\n",
    "                    \"gt\": gt,\n",
    "                    \"model_index\": i,\n",
    "                    \"model_output\": mo,\n",
    "                    \"pred\": pred\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if wrong_entries:\n",
    "        with open(wrong_file_path, 'w', encoding='utf-8') as wf:\n",
    "            for we in wrong_entries:\n",
    "                wf.write(json.dumps(we, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"Saved wrong predictions to {wrong_file_path}\")\n",
    "    else:\n",
    "        print(\"No wrong entries found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e589dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
