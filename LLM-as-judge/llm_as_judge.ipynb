{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehdtjr1220/miniconda3/envs/proj2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "sys.path.append('../')  \n",
    "\n",
    "from gpqa.gpqa_utils import * \n",
    "\n",
    "from math500.math_utils import * \n",
    "from math500.parser import *\n",
    "from math500.grader import * \n",
    "\n",
    "from mmlu_pro.mmlu_utils import * \n",
    "\n",
    "from hotpotqa.hotpotqa_utils import *\n",
    "\n",
    "from drop.drop_utils import *\n",
    "\n",
    "from musr.musr import MuSRDataset\n",
    "\n",
    "from utils import load_model_outputs\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def load_data_and_fewshot(args):\n",
    "    if args.task == \"mmlu_pro\":\n",
    "        dataset, fewshot = load_mmlu_pro()\n",
    "\n",
    "    elif args.task == \"math500\": \n",
    "        file_path = f\"../data/math500/test.jsonl\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            dataset = [json.loads(line) for line in f]\n",
    "        fewshot = load_prompt(num_shots=5)\n",
    "    \n",
    "    elif args.task == \"gpqa\":\n",
    "        dataset = load_examples(\"../data/gpqa/gpqa_diamond.csv\", seed=0)\n",
    "        with open(\"../gpqa/chain_of_thought_examples.json\", 'r') as f:\n",
    "            fewshot = json.load(f)\n",
    "\n",
    "    elif args.task == \"hotpotqa\":\n",
    "        dataset = json.load(open(f'../data/hotpotqa/{args.task}.json'))\n",
    "        with open(\"../hotpotqa/react_prompt.json\", 'r') as f:\n",
    "            fewshot = json.load(f)\n",
    "\n",
    "    elif args.task == \"drop\":\n",
    "        dataset = pd.read_parquet(\"../data/drop/drop_sub.parquet\", engine=\"pyarrow\")\n",
    "        dataset = dataset.to_dict(orient=\"records\")  \n",
    "\n",
    "        dataset = convert_ndarray_to_list(dataset)\n",
    "        dataset = convert_ndarray_to_list(dataset)\n",
    "\n",
    "        with open(\"../drop/prompt.json\", 'r') as f:\n",
    "            fewshot = json.load(f)\n",
    "\n",
    "    elif args.task == \"musr_efficiently\":\n",
    "        ta_path = '../data/musr/team_allocation.json'\n",
    "        dataset = MuSRDataset(ta_path)\n",
    "        fewshot = 1\n",
    "\n",
    "    elif args.task == \"musr_location\":\n",
    "        op_path = '../data/musr/object_placements.json'\n",
    "        dataset = MuSRDataset(op_path)\n",
    "        fewshot = 1\n",
    "    else: \n",
    "        return None, None\n",
    "    \n",
    "    return dataset, fewshot\n",
    "\n",
    "def construct_prompt(args, dataset, fewshot): \n",
    "    system_prompt = (\n",
    "        \"Your job is selecting the most accurate response among multiple candidates. \"\n",
    "        \"You will receive a question and several candidate answers labeled candidate1, candidate2, etc. \"\n",
    "        \"Please summarize the debate very briefly and then conclude which single candidate is the most plausible. \"\n",
    "        \"Output exactly in this format:\\n\"\n",
    "        \"Summary: <brief summary>\\n\"\n",
    "        \"Conclusion: candidate<number>\\n\"\n",
    "        \"Remember to choose only one candidate as the final answer.\\n\"\n",
    "    )\n",
    "    before_fewshot = \"The below examples are well-constructed gold question and answer pairs for the same task.\\n\\n\"\n",
    "    before_question = \"Now, letâ€™s select the most proper answer for the given question\\n\"\n",
    "\n",
    "    output_res_path = f\"{args.input_dir}/{args.task}/{args.model}\"\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    if args.task == \"math500\":\n",
    "        output_res_path = os.path.join(output_res_path, f\"{args.task}_few.jsonl\")\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "        start_prompt = \"Please reason step by step, and put your final answer within \\\\boxed{{}}.\\n\\n\"\n",
    "        for idx, r in tqdm(enumerate(res)):\n",
    "            entry = r.get('entry', {})\n",
    "            question = entry.get('problem', '')\n",
    "            model_outputs = r.get('model_outputs', [])\n",
    "\n",
    "            user_prompt = start_prompt + before_fewshot\n",
    "\n",
    "            if fewshot != None: \n",
    "                user_prompt += \"\\n\\n\".join([f\"{q}\\n\\n{a}\" for q, a in fewshot]) + \"\\n\\n\" \n",
    "\n",
    "            user_prompt += before_question\n",
    "\n",
    "            user_prompt += f\"Question: {question}\\n\"\n",
    "\n",
    "            for i, output in enumerate(model_outputs, start=1):\n",
    "                user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "                \n",
    "            message = [{\"role\": \"system\",\"content\": system_prompt},{\"role\": \"user\",\"content\": user_prompt}]\n",
    "            sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "            samples.append(sample)\n",
    "        \n",
    "    elif args.task == \"mmlu_pro\":\n",
    "        subjects = list(dataset.keys())\n",
    "        for subject in tqdm(subjects): \n",
    "            res_path = os.path.join(output_res_path, f\"{subject}_result.jsonl\")\n",
    "            res = load_model_outputs(res_path)\n",
    "            \n",
    "            start_prompt = \"The following are multiple choice questions (with answers) about {}. Think step by\" \\\n",
    "                \" step and then output the answer in the format of \\\"The answer is (X)\\\" at the end.\\n\\n\" \\\n",
    "            .format(subject)\n",
    "\n",
    "            start_prompt += before_fewshot\n",
    "\n",
    "            if fewshot != None:\n",
    "                for each in fewshot[subject]:\n",
    "                    start_prompt += format_example(each[\"question\"], each[\"options\"], each[\"cot_content\"])\n",
    "            \n",
    "            start_prompt += before_question\n",
    "            \n",
    "\n",
    "            random.seed(42)\n",
    "            test_data = random.sample(dataset[subject], min(300, len(dataset[subject])))\n",
    "            \n",
    "            for idx, (entry, r) in enumerate(zip(test_data, res)):\n",
    "                entry = r.get('entry', {})\n",
    "                model_outputs = r.get('model_outputs', [])\n",
    "                question = format_example(entry['question'], entry['options'])\n",
    "                \n",
    "                user_prompt = start_prompt + f\"{question}\\n\"\n",
    "                for i, output in enumerate(model_outputs, start=1):\n",
    "                    user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "\n",
    "                message = [\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ]\n",
    "\n",
    "                sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "                samples.append(sample)\n",
    "    \n",
    "    elif args.task == \"gpqa\": \n",
    "        def chain_of_thought_prompt(json_data, example: Example) -> str:\n",
    "            \"\"\"Creates a chain-of-thought prompt given a single example.\"\"\"\n",
    "            prompt = f\"Here are some example questions from experts. An explanation is given before the final answer. Answer the final question yourself, giving your reasoning beforehand.\\n\"\n",
    "            prompt += generate_prompt_from_examples(json_data, with_explanations=True)\n",
    "            prompt += before_question\n",
    "            prompt += f\"Question: {example.question}\"\n",
    "            prompt += f\"\\nChoices:\\n(A) {example.choice1}\\n(B) {example.choice2}\\n(C) {example.choice3}\\n(D) {example.choice4}\"\n",
    "            prompt += \"\\nGive step by step reasoning before you answer, and when you're ready to answer, please use the format \\\"The correct answer is (insert answer here)\\\":\\n\"\n",
    "            return prompt\n",
    "        \n",
    "        output_res_path = os.path.join(output_res_path, f\"{args.task}_few.jsonl\")\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "\n",
    "        start_prompt = \"You are a very intelligent assistant, who follows instructions directly.\\n\\n\"\n",
    "        start_prompt += before_fewshot\n",
    "        for idx, (example, r) in enumerate(zip(dataset, res)):\n",
    "            user_prompt = start_prompt\n",
    "\n",
    "            if fewshot != None: \n",
    "                user_prompt += chain_of_thought_prompt(fewshot, example)\n",
    "            \n",
    "            entry = r.get('entry', {})\n",
    "            model_outputs = r.get('model_outputs', [])\n",
    "\n",
    "            for i, output in enumerate(model_outputs, start=1):\n",
    "                user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "\n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "            samples.append(sample)\n",
    "\n",
    "    elif args.task == \"hotpotqa\": \n",
    "        output_res_path = os.path.join(output_res_path, f\"{args.task}_few.jsonl\")\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "\n",
    "        if fewshot != None: \n",
    "            fewshot_prompt = before_fewshot\n",
    "            for qa in fewshot:\n",
    "                question = qa[\"Q\"]\n",
    "                answer = qa[\"A\"]\n",
    "\n",
    "                fewshot_prompt += f\"Q: {question}\\nA: {answer}\\n\\n\"\n",
    "        fewshot_prompt += before_question\n",
    "\n",
    "        for idx, (entry, r) in enumerate(zip(dataset, res)):\n",
    "            if fewshot != None: \n",
    "                user_prompt = fewshot_prompt + f\"Q: {entry['question']}.\" + \"\\n\\nEnd your answer with \\\"Answer <answer>\\\". Think step by step.\" + \"\\n\\n\" \n",
    "            \n",
    "            entry = r.get('entry', {})\n",
    "            model_outputs = r.get('model_outputs', [])\n",
    "\n",
    "            for i, output in enumerate(model_outputs, start=1):\n",
    "                user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "\n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "            samples.append(sample)\n",
    "\n",
    "    elif args.task == \"drop\": \n",
    "        output_res_path = os.path.join(output_res_path, f\"{args.task}_few.jsonl\")\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "\n",
    "        if fewshot != None: \n",
    "            fewshot_prompt = before_fewshot\n",
    "            for qa in fewshot:\n",
    "                question = qa[\"Q\"]\n",
    "                answer = qa[\"A\"]\n",
    "\n",
    "                fewshot_prompt += f\"Q: {question}\\nA: {answer}\\n\\n\"\n",
    "        fewshot_prompt += before_question\n",
    "\n",
    "        for idx, (entry, r) in enumerate(zip(dataset, res)):\n",
    "            if fewshot != None: \n",
    "                user_prompt = fewshot_prompt + f\"Q: {entry['passage']} {entry['question']}\" + \"\\n\\nEnd your answer with \\\"So the answer is <answer>\\\". Think step by step.\" + \"\\n\\n\"\n",
    "            \n",
    "            entry = r.get('entry', {})\n",
    "            model_outputs = r.get('model_outputs', [])\n",
    "\n",
    "            for i, output in enumerate(model_outputs, start=1):\n",
    "                user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "\n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "            samples.append(sample)\n",
    "\n",
    "    elif args.task == \"musr_efficiently\" or args.task == \"musr_location\":\n",
    "        from musr.op_icl_fixed import op_fewshot, few_shot_op_instruction, test_op_instruction\n",
    "        from musr.ta_icl_fixed import ta_fewshot, few_shot_ta_instruction, test_ta_instruction\n",
    "\n",
    "        if args.task == \"musr_location\":\n",
    "            few_shot_examples = op_fewshot  \n",
    "            few_instruction = few_shot_op_instruction\n",
    "            test_instruction = test_op_instruction\n",
    "        elif args.task == 'musr_efficiently':\n",
    "            few_shot_examples = ta_fewshot\n",
    "            few_instruction = few_shot_ta_instruction\n",
    "            test_instruction = test_ta_instruction\n",
    "\n",
    "        output_res_path = os.path.join(output_res_path, f\"{args.task}_few.jsonl\")\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "        for idx, (entry, r) in enumerate(zip(dataset, res)):\n",
    "            model_outputs = r.get('model_outputs', [])\n",
    "\n",
    "            question = entry['question'].strip()\n",
    "            context = entry['context'].strip()\n",
    "            choices = entry['choices']['text']\n",
    "            labels = ['A', 'B', 'C', 'D', 'E', 'F'][:len(choices)]\n",
    "            choice_str = '\\n'.join([f'{labels[idx]}: {choices[idx]}' for idx in range(len(choices))])\n",
    "            original_question_part = f\"{context}\\n\\n{question}\\n\\n{choice_str}\"\n",
    "            start_prompt = entry['prompt_parts']['cot_system_prompt'] + \"\\n\\n\" + before_fewshot\n",
    "            \n",
    "            user_prompt = start_prompt\n",
    "            for (q, a) in few_shot_examples:\n",
    "                user_prompt += q + \"\\n\\n\" + few_instruction + \"\\n\"\n",
    "                user_prompt += a + \"\\n\\n\"\n",
    "\n",
    "            user_prompt += before_question\n",
    "            user_prompt += original_question_part + \"\\n\\n\" + test_instruction + \"\\n\"\n",
    "\n",
    "            for i, output in enumerate(model_outputs, start=1):\n",
    "                user_prompt += f\"candidate{i}: {output}\\n\"\n",
    "            \n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            sample = {\"idx\": idx, \"prompt\": message, \"entry\": entry}\n",
    "            samples.append(sample)\n",
    "\n",
    "\n",
    "    else: \n",
    "        return None\n",
    "        \n",
    "    return samples\n",
    "\n",
    "def generate_model_output(model: str, prompt: str, temperature: float = 1.0, n: int = 1) -> str:        \n",
    "    responses = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=prompt,\n",
    "        n=1,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    outputs = [choice.message.content for choice in responses.choices]\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "\n",
    "    save_path = f\"{config.output_dir}/{config.task}/{config.model}/{config.task}_{config.shot_type}.jsonl\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        \n",
    "    dataset, fewshot = load_data_and_fewshot(config)\n",
    "    if config.shot_type == \"zero\":\n",
    "        fewshot = None\n",
    "        \n",
    "    samples = construct_prompt(config, dataset, fewshot)\n",
    "    if config.num_examples != -1: \n",
    "        samples = samples[:config.num_examples]\n",
    "\n",
    "    if samples:\n",
    "        print(f\"Model: {config.model} Task: {config.task}, Shot: {config.shot_type}\")\n",
    "        print(samples[0].keys())\n",
    "        print(\"-\" * 50)\n",
    "        prompt = samples[0][\"prompt\"]\n",
    "        for message in prompt:\n",
    "            print(f\"Role:\\n{message['role']}\")\n",
    "            print(f\"Content:\\n{message['content']}\")\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\"No samples found for Task: {config.task}, Shot: {config.shot_type}\")\n",
    "\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'r', encoding='utf-8') as f:\n",
    "\n",
    "            existing_data = {json.loads(line)['prompt'][1]['content'] for line in f}  \n",
    "\n",
    "    else:\n",
    "        existing_data = set()  \n",
    "\n",
    "\n",
    "    if samples:\n",
    "\n",
    "        with open(save_path, \"a\", encoding='utf-8') as f:  \n",
    "\n",
    "            for sample in tqdm(samples, total=len(samples)):\n",
    "                if sample['prompt'][1]['content'] in existing_data:  \n",
    "\n",
    "                    continue\n",
    "                try:\n",
    "\n",
    "                    model_outputs = generate_model_output(config.model, sample[\"prompt\"], config.temperature)\n",
    "                    sample[\"prompt_output\"] = model_outputs\n",
    "                    json.dump(sample, f)\n",
    "                    f.write(\"\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing sample {sample['idx']}: {e}\")\n",
    "                    break\n",
    "\n",
    "        print(f\"Results saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.model = \"gpt-4o-mini\"  \n",
    "        self.task = \"drop\"  # \"math500\", \"mmlu_pro\", \"gpqa\", \"drop\", \"hotpotqa\"\n",
    "        self.shot_type = \"few\"  \n",
    "        self.output_dir = \"llm_as_judge\"\n",
    "        self.input_dir = \"../result\"\n",
    "        self.num_examples = -1\n",
    "        self.temperature = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tasks = ['math500']\n",
    "subjects = ['business', 'law', 'psychology', 'biology', 'chemistry', 'history', 'other', 'health', 'economics', 'math', 'physics', 'computer science', 'philosophy', 'engineering']\n",
    "\n",
    "shots = [\"few\"]\n",
    "models = ['gpt-4o-mini']\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:00, 66453.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4o-mini Task: math500, Shot: few\n",
      "dict_keys(['idx', 'prompt', 'entry'])\n",
      "--------------------------------------------------\n",
      "Role:\n",
      "system\n",
      "Content:\n",
      "Your job is selecting the most accurate response among multiple candidates. You will receive a question and several candidate answers labeled candidate1, candidate2, etc. Please summarize the debate very briefly and then conclude which single candidate is the most plausible. Output exactly in this format:\n",
      "Summary: <brief summary>\n",
      "Conclusion: candidate<number>\n",
      "Remember to choose only one candidate as the final answer.\n",
      "\n",
      "--------------------------------------------------\n",
      "Role:\n",
      "user\n",
      "Content:\n",
      "Please reason step by step, and put your final answer within \\boxed{{}}.\n",
      "\n",
      "The below examples are well-constructed gold question and answer pairs for the same task.\n",
      "\n",
      "Kevin Kangaroo begins hopping on a number line at 0. He wants to get to 1, but he can hop only $\\frac{1}{3}$ of the distance. Each hop tires him out so that he continues to hop $\\frac{1}{3}$ of the remaining distance. How far has he hopped after five hops? Express your answer as a common fraction.\n",
      "\n",
      "Let's think step by step\n",
      "Kevin hops $1/3$ of the remaining distance with every hop.\n",
      "His first hop takes $1/3$ closer.\n",
      "For his second hop, he has $2/3$ left to travel, so he hops forward $(2/3)(1/3)$.\n",
      "For his third hop, he has $(2/3)^2$ left to travel, so he hops forward $(2/3)^2(1/3)$.\n",
      "In general, Kevin hops forward $(2/3)^{k-1}(1/3)$ on his $k$th hop.\n",
      "We want to find how far he has hopped after five hops.\n",
      "This is a finite geometric series with first term $1/3$, common ratio $2/3$, and five terms.\n",
      "Thus, Kevin has hopped $\\frac{\\frac{1}{3}\\left(1-\\left(\\frac{2}{3}\\right)^5\\right)}{1-\\frac{2}{3}} = \\boxed{\\frac{211}{243}}$.\n",
      "The answer is \\frac{211}{243}}\n",
      "\n",
      "What is the area of the region defined by the equation $x^2+y^2 - 7 = 4y-14x+3$?\n",
      "\n",
      "Let's think step by step\n",
      "We rewrite the equation as $x^2 + 14x + y^2 - 4y = 10$ and then complete the square,\n",
      "resulting in  $(x+7)^2-49 + (y-2)^2-4=10$,\n",
      "or $(x+7)^2+(y-2)^2=63$.\n",
      "This is the equation of a circle with center $(-7, 2)$ and radius $\\sqrt{63},$\n",
      "so the area of this region is $\\pi r^2 = \\boxed{63\\pi}$.\n",
      "The answer is 63\\pi\n",
      "\n",
      "If $x^2+y^2=1$, what is the largest possible value of $|x|+|y|$?\n",
      "\n",
      "Let's think step by step\n",
      "If $(x,y)$ lies on the circle,\n",
      "so does $(x,-y),$ $(-x,-y),$ and $(-x,-y),$ (which all give the same value of $|x| + |y|$),\n",
      "so we can assume that $x \\ge 0$ and $y \\ge 0.$\n",
      "Then $|x| + |y| = x + y.$  Squaring, we get\n",
      "\\[(x + y)^2 = x^2 + 2xy + y^2 = 1 + 2xy.\\]\n",
      "Note that $(x - y)^2 \\ge 0.$\n",
      "Expanding, we get $x^2 - 2xy + y^2 \\ge 0,$ so $2xy \\le x^2 + y^2 = 1.$\n",
      "Hence,\\[1 + 2xy \\le 2,\\]which means $x + y \\le \\sqrt{2}.$\n",
      "Equality occurs when $x = y = \\frac{1}{\\sqrt{2}},$\n",
      "so the maximum value of $|x| + |y|$ is $\\boxed{\\sqrt{2}}.$\n",
      "The answer is \\sqrt{2}\n",
      "\n",
      "If $f(x)=\\frac{ax+b}{cx+d}, abcd\\not=0$ and $f(f(x))=x$ for all $x$ in the domain of $f$, what is the value of $a+d$?\n",
      "\n",
      "Let's think step by step\n",
      "The condition $f(f(x))$ means that $f$ is the inverse of itself,\n",
      "so its graph is symmetrical about the line $y = x$.\n",
      "With a rational function of this form, we will have two asymptotes:\n",
      "a vertical one at $x=-d/c$ if $cx+d$ does not divide $ax+b$,\n",
      "and a horizontal one at $y=a/c$,\n",
      "if we take the limit of $f(x)$ as $x$ goes to $\\pm\\infty$.\n",
      "In order for $f$ to be its own inverse, the intersection of the asymptotes must lie on the line $y=x$\n",
      "so that it and its asymptotes reflect onto themselves.\n",
      "This means that $-d/c=a/c$,\n",
      "and therefore $-d=a$ and $a+d=\\boxed{0}$.\n",
      "The answer is 0\n",
      "\n",
      "Expand $(2z^2 + 5z - 6)(3z^3 - 2z + 1)$.\n",
      "\n",
      "Let's think step by step\n",
      "$$\\begin{array}{crrrrrrr}\n",
      "& & & 3z^3 & & -2z & + 1 & \\\\\n",
      "\\times & & & & 2z^2 & +5z & -6 \\\\\n",
      "\\cline{1-7}\\rule{0pt}{0.17in}\n",
      "& & & -18z^3 & & +12z & -6 & \\\\\n",
      "& & +15z^4 & & -10z^2 & +5z & & \\\\\n",
      "+ & 6z^5 & & -4z^3 & +2z^2 & & & \\\\\n",
      "\\cline{1-7}\\rule{0pt}{0.17in}\n",
      "& 6z^5 & +15z^4 & -22z^3 & - 8z^2 &+17z & -6 &\n",
      "\\end{array}$$\n",
      "The answer is 6z^5+15z^4-22z^3-8z^2+17z-6\n",
      "\n",
      "Now, letâ€™s select the most proper answer for the given question\n",
      "Question: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
      "candidate1: To convert the point \\((0, 3)\\) from rectangular coordinates to polar coordinates, we need to determine the values of \\(r\\) and \\(\\theta\\).\n",
      "\n",
      "1. **Calculate \\(r\\)**:\n",
      "   The polar coordinate \\(r\\) is the distance from the origin to the point \\((x, y)\\). It can be calculated using the formula:\n",
      "   \\[\n",
      "   r = \\sqrt{x^2 + y^2}\n",
      "   \\]\n",
      "   For our point \\((0, 3)\\):\n",
      "   \\[\n",
      "   r = \\sqrt{0^2 + 3^2} = \\sqrt{0 + 9} = \\sqrt{9} = 3\n",
      "   \\]\n",
      "\n",
      "2. **Calculate \\(\\theta\\)**:\n",
      "   The angle \\(\\theta\\) is calculated from the positive x-axis. Since the point \\((0, 3)\\) lies directly above the origin on the y-axis, \\(\\theta\\) can be determined as:\n",
      "   \\[\n",
      "   \\theta = \\frac{\\pi}{2}\n",
      "   \\]\n",
      "   This is because the positive y-axis corresponds to the angle \\(\\frac{\\pi}{2}\\) radians in polar coordinates.\n",
      "\n",
      "3. **Combine the results**:\n",
      "   Therefore, the polar coordinates of the point \\((0, 3)\\) are:\n",
      "   \\[\n",
      "   (r, \\theta) = (3, \\frac{\\pi}{2})\n",
      "   \\]\n",
      "\n",
      "Thus, the final answer, in the form \\((r, \\theta)\\), is:\n",
      "\\[\n",
      "\\boxed{(3, \\frac{\\pi}{2})}\n",
      "\\]\n",
      "candidate2: To convert the point \\((0,3)\\) from rectangular coordinates to polar coordinates, we need to find the values of \\(r\\) and \\(\\theta\\).\n",
      "\n",
      "1. The formula for the radial coordinate \\(r\\) in polar coordinates is given by:\n",
      "   \\[\n",
      "   r = \\sqrt{x^2 + y^2}\n",
      "   \\]\n",
      "   For our point \\((0,3)\\):\n",
      "   \\[\n",
      "   r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3\n",
      "   \\]\n",
      "\n",
      "2. The angular coordinate \\(\\theta\\) is determined by the arctangent of the ratio \\(y/x\\):\n",
      "   \\[\n",
      "   \\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right)\n",
      "   \\]\n",
      "   For our point, since \\(x = 0\\) and \\(y = 3\\), we have:\n",
      "   \\[\n",
      "   \\theta = \\tan^{-1}\\left(\\frac{3}{0}\\right)\n",
      "   \\]\n",
      "   This situation corresponds to \\(x = 0\\) and \\(y > 0\\), which occurs at \\(\\theta = \\frac{\\pi}{2}\\).\n",
      "\n",
      "Thus, the rectangular coordinates \\((0,3)\\) convert to the polar coordinates \\((r, \\theta)\\):\n",
      "\\[\n",
      "(r, \\theta) = (3, \\frac{\\pi}{2})\n",
      "\\]\n",
      "\n",
      "Putting this in the required format, we have the final answer:\n",
      "\n",
      "\\[\n",
      "\\boxed{(3, \\frac{\\pi}{2})}\n",
      "\\]\n",
      "candidate3: To convert the point \\((0, 3)\\) in rectangular coordinates to polar coordinates, we need to find the values of \\(r\\) and \\(\\theta\\).\n",
      "\n",
      "1. **Calculate \\(r\\)**:  \n",
      "   The polar coordinate \\(r\\) is given by the distance from the point to the origin. This is calculated using the formula:\n",
      "   \\[\n",
      "   r = \\sqrt{x^2 + y^2}\n",
      "   \\]\n",
      "   Substituting \\(x = 0\\) and \\(y = 3\\):\n",
      "   \\[\n",
      "   r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3\n",
      "   \\]\n",
      "\n",
      "2. **Calculate \\(\\theta\\)**:  \n",
      "   The angle \\(\\theta\\) is found using the arctangent function, which gives the angle corresponding to the coordinates:\n",
      "   \\[\n",
      "   \\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right)\n",
      "   \\]\n",
      "   Here \\(x = 0\\) and \\(y = 3\\). Since \\(x\\) is 0 and \\(y\\) is positive, the point lies on the positive \\(y\\)-axis, which corresponds to:\n",
      "   \\[\n",
      "   \\theta = \\frac{\\pi}{2}\n",
      "   \\]\n",
      "\n",
      "Thus, the polar coordinates are:\n",
      "\\[\n",
      "(r, \\theta) = (3, \\frac{\\pi}{2})\n",
      "\\]\n",
      "\n",
      "Putting this in the required format:\n",
      "\\[\n",
      "\\boxed{(3, \\frac{\\pi}{2})}\n",
      "\\]\n",
      "candidate4: To convert the point \\((0, 3)\\) from rectangular coordinates to polar coordinates, we use the formulas for polar coordinates:\n",
      "\n",
      "- The radial distance \\( r \\) is given by:\n",
      "  \\[\n",
      "  r = \\sqrt{x^2 + y^2}\n",
      "  \\]\n",
      "- The angle \\( \\theta \\) is given by:\n",
      "  \\[\n",
      "  \\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right)\n",
      "  \\]\n",
      "\n",
      "Step 1: Calculate \\( r \\):\n",
      "\\[\n",
      "x = 0, \\quad y = 3\n",
      "\\]\n",
      "\\[\n",
      "r = \\sqrt{0^2 + 3^2} = \\sqrt{9} = 3\n",
      "\\]\n",
      "\n",
      "Step 2: Calculate \\( \\theta \\):\n",
      "Since \\( x = 0 \\) and \\( y = 3 > 0 \\), the point lies on the positive \\( y \\)-axis. In this case, the angle \\( \\theta \\) corresponding to the positive \\( y \\)-axis is:\n",
      "\\[\n",
      "\\theta = \\frac{\\pi}{2}\n",
      "\\]\n",
      "\n",
      "Putting it all together, the polar coordinates are:\n",
      "\\[\n",
      "(r, \\theta) = (3, \\frac{\\pi}{2})\n",
      "\\]\n",
      "\n",
      "Thus, the final answer is \\(\\boxed{(3, \\frac{\\pi}{2})}\\).\n",
      "candidate5: To convert the point \\((0, 3)\\) from rectangular coordinates to polar coordinates, we apply the formulas for conversion:\n",
      "\n",
      "1. The radius \\(r\\) can be calculated using the formula:\n",
      "   \\[\n",
      "   r = \\sqrt{x^2 + y^2}\n",
      "   \\]\n",
      "   where \\(x = 0\\) and \\(y = 3\\).\n",
      "\n",
      "   Substituting the values, we get:\n",
      "   \\[\n",
      "   r = \\sqrt{0^2 + 3^2} = \\sqrt{0 + 9} = \\sqrt{9} = 3.\n",
      "   \\]\n",
      "\n",
      "2. The angle \\(\\theta\\) is determined using the formula:\n",
      "   \\[\n",
      "   \\theta = \\tan^{-1}\\left(\\frac{y}{x}\\right).\n",
      "   \\]\n",
      "   However, since \\(x = 0\\), we cannot directly use this formula. When \\(x = 0\\), the angle \\(\\theta\\) corresponds to the positive \\(y\\)-axis.\n",
      "\n",
      "   In standard polar coordinate conventions:\n",
      "   - If \\(y > 0\\), \\(\\theta = \\frac{\\pi}{2}\\).\n",
      "   - If \\(y < 0\\), \\(\\theta = \\frac{3\\pi}{2}\\).\n",
      "\n",
      "   Since \\(y = 3\\) (which is positive), it follows that:\n",
      "   \\[\n",
      "   \\theta = \\frac{\\pi}{2}.\n",
      "   \\]\n",
      "\n",
      "Thus, the polar coordinates for the point \\((0, 3)\\) are:\n",
      "\n",
      "\\[\n",
      "(r, \\theta) = (3, \\frac{\\pi}{2}).\n",
      "\\]\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "\\(\\boxed{(3, \\frac{\\pi}{2})}\\)\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 67003.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to llm_prompt_with_fewshot/math500/gpt-4o-mini/math500_few.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model in models:\n",
    "    for task in tasks:\n",
    "        for shot in shots:\n",
    "            config.model = model\n",
    "            config.task = task\n",
    "            config.shot_type = shot\n",
    "            print(\"=\" * 50)\n",
    "            main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_number(response_text):\n",
    "    primary_pattern = r'\\[?\\s*Conclusion: candidate\\s*(\\d+)\\s*\\]?'\n",
    "    primary_matches = re.findall(primary_pattern, response_text, flags=re.IGNORECASE)\n",
    "    if primary_matches:\n",
    "\n",
    "        return int(primary_matches[0])\n",
    "    \n",
    "\n",
    "\n",
    "    sentences = re.split(r'[.\\n]', response_text.strip())\n",
    "\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    if sentences:\n",
    "        last_sentence = sentences[-1]\n",
    "        fallback_matches = re.findall(r'(\\d+)', last_sentence)\n",
    "        if fallback_matches:\n",
    "\n",
    "            return int(fallback_matches[-1])\n",
    "    \n",
    "\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gpt-4o-mini-math500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 57296.10it/s]\n",
      "Processing gpt-4o-mini-gpqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 45728.33it/s]\n",
      "Processing gpt-4o-mini-drop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 69133.08it/s]\n",
      "Processing gpt-4o-mini-hotpotqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 60426.21it/s]\n",
      "Processing gpt-4o-mini-musr_efficiently: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00<00:00, 44006.04it/s]\n",
      "Processing gpt-4o-mini-musr_location: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 54328.16it/s]\n",
      "Processing gpt-4o-math500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 46460.90it/s]\n",
      "Processing gpt-4o-gpqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 39291.83it/s]\n",
      "Processing gpt-4o-drop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 70744.57it/s]\n",
      "Processing gpt-4o-hotpotqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 58589.48it/s]\n",
      "Processing gpt-4o-musr_efficiently: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00<00:00, 40043.38it/s]\n",
      "Processing gpt-4o-musr_location: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 45749.55it/s]\n",
      "Processing llama-math500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 86924.98it/s]\n",
      "Processing llama-gpqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198/198 [00:00<00:00, 67921.17it/s]\n",
      "Processing llama-drop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 96416.35it/s]\n",
      "Processing llama-hotpotqa: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 86541.16it/s]\n",
      "Processing llama-musr_efficiently: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00<00:00, 58691.15it/s]\n",
      "Processing llama-musr_location: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256/256 [00:00<00:00, 56058.36it/s]\n"
     ]
    }
   ],
   "source": [
    "overall_summary = []\n",
    "\n",
    "for model in ['gpt-4o-mini', 'gpt-4o', 'llama']:\n",
    "    for task in tasks:\n",
    "        if task == 'mmlu_pro':\n",
    "            continue\n",
    "        prompting_path = f\"{config.output_dir}/{task}/{model}/{task}_{config.shot_type}.jsonl\"\n",
    "        llm_prompt = load_model_outputs(prompting_path)\n",
    "\n",
    "        output_res_path = f\"../result/{task}/{model}/{task}_{config.shot_type}.jsonl\"\n",
    "        res = load_model_outputs(output_res_path)\n",
    "                    \n",
    "\n",
    "        user_counter = Counter()\n",
    "        total_entries = 0\n",
    "        for entry in tqdm(llm_prompt, desc=f\"Processing {model}-{task}\"):\n",
    "            total_entries += 1\n",
    "            raw_output = entry.get(\"prompt_output\")          \n",
    "            if isinstance(raw_output, list):\n",
    "                prompt_output = raw_output[0] if raw_output else None\n",
    "            else:\n",
    "                prompt_output = raw_output                   \n",
    "\n",
    "            if prompt_output is None:\n",
    "                user_counter[\"None\"] += 1\n",
    "                continue\n",
    "            extracted_user = extract_user_number(prompt_output)\n",
    "            if extracted_user is None:\n",
    "                user_counter[\"None\"] += 1\n",
    "            else:\n",
    "                user_counter[extracted_user] += 1\n",
    "\n",
    "\n",
    "        for user, count in user_counter.items():\n",
    "            percentage = (count / total_entries) * 100 if total_entries else 0\n",
    "            overall_summary.append({\n",
    "                \"Model\": model,\n",
    "                \"Task\": task,\n",
    "                \"Extracted User\": user,\n",
    "                \"Count\": count,\n",
    "                \"Percentage\": round(percentage, 2)\n",
    "            })\n",
    "\n",
    "        for i in range(len(res)):\n",
    "            raw_output = llm_prompt[i].get(\"prompt_output\")          \n",
    "            if isinstance(raw_output, list):\n",
    "                source_text = raw_output[0] if raw_output else None\n",
    "            else:\n",
    "                source_text = raw_output                   \n",
    "\n",
    "            if source_text is None:\n",
    "                answer_number = 1\n",
    "            else:\n",
    "                answer_number = extract_user_number(source_text)\n",
    "                if not isinstance(answer_number, int) or not (1 <= answer_number <= 5):\n",
    "                    answer_number = 1\n",
    "            model_outputs = res[i].get('model_outputs') or res[i].get('resps')[0]\n",
    "            if len(model_outputs) < answer_number:\n",
    "                print(f\"Warning: Entry {i} has less than {answer_number} model outputs. Using default output.\")\n",
    "                chosen_output = model_outputs[0] if model_outputs else None\n",
    "            else:\n",
    "                chosen_output = model_outputs[answer_number-1]\n",
    "            llm_prompt[i]['prompt_output_with_fewshot'] = chosen_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>95.96</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task     drop   gpqa  hotpotqa  math500  musr_efficiently  musr_location\n",
       "Group                                                                   \n",
       "1-5     100.0  95.96     100.0    100.0             100.0          100.0\n",
       "Others    0.0   4.04       0.0      0.0               0.0            0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task    drop    gpqa  hotpotqa  math500  musr_efficiently  musr_location\n",
       "Group                                                                   \n",
       "1-5    100.0  100.02     100.0    100.0             100.0         100.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: llama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>84.4</td>\n",
       "      <td>94.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task     drop    gpqa  hotpotqa  math500  musr_efficiently  musr_location\n",
       "Group                                                                    \n",
       "1-5     100.0  100.01     100.0     99.8              84.4          94.92\n",
       "Others    0.0    0.00       0.0      0.2              15.6           5.08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_overall = pd.DataFrame(overall_summary)\n",
    "\n",
    "\n",
    "df_overall['ExtractedUser_Num'] = pd.to_numeric(\n",
    "    df_overall['Extracted User'], errors='coerce'\n",
    ")\n",
    "\n",
    "\n",
    "df_overall['Group'] = df_overall['ExtractedUser_Num'].apply(\n",
    "    lambda x: '1-5' if 1 <= x <= 5 else 'Others'\n",
    ")\n",
    "\n",
    "for model in df_overall[\"Model\"].unique():\n",
    "    model_df = df_overall[df_overall[\"Model\"] == model]\n",
    "    \n",
    "\n",
    "    pivot_table = model_df.pivot_table(\n",
    "        index=\"Group\",         \n",
    "        columns=\"Task\",         \n",
    "        values=\"Percentage\",    \n",
    "        aggfunc=\"sum\",          \n",
    "        fill_value=0            \n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel: {model}\")\n",
    "    display(pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>37.37</td>\n",
       "      <td>62.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>85.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.2</td>\n",
       "      <td>26.26</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>36.4</td>\n",
       "      <td>7.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.2</td>\n",
       "      <td>16.67</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.8</td>\n",
       "      <td>10.61</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage                                           \\\n",
       "Task                 drop   gpqa hotpotqa math500 musr_efficiently   \n",
       "Extracted User                                                       \n",
       "-1                    0.0   4.04      0.0     0.0              0.0   \n",
       " 1                   85.0  37.37     62.2    91.0             34.4   \n",
       " 2                    9.2  26.26     16.6     4.6             36.4   \n",
       " 3                    2.2  16.67      8.6     1.0             27.2   \n",
       " 4                    2.8  10.61      8.0     2.4              0.0   \n",
       " 5                    0.8   5.05      4.6     1.0              2.0   \n",
       "\n",
       "                              \n",
       "Task           musr_location  \n",
       "Extracted User                \n",
       "-1                      0.00  \n",
       " 1                     85.16  \n",
       " 2                      7.81  \n",
       " 3                      3.91  \n",
       " 4                      1.17  \n",
       " 5                      1.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.8</td>\n",
       "      <td>70.71</td>\n",
       "      <td>69.2</td>\n",
       "      <td>79.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.4</td>\n",
       "      <td>15.66</td>\n",
       "      <td>10.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>24.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.8</td>\n",
       "      <td>6.57</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>2.53</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage                                           \\\n",
       "Task                 drop   gpqa hotpotqa math500 musr_efficiently   \n",
       "Extracted User                                                       \n",
       "1                    93.8  70.71     69.2    79.2             30.0   \n",
       "2                     3.4  15.66     10.4    13.0             35.6   \n",
       "3                     1.8   6.57      8.2     5.0             21.6   \n",
       "4                     0.2   2.53      6.2     1.4              3.6   \n",
       "5                     0.8   4.55      6.0     1.4              9.2   \n",
       "\n",
       "                              \n",
       "Task           musr_location  \n",
       "Extracted User                \n",
       "1                      62.50  \n",
       "2                      24.22  \n",
       "3                       5.08  \n",
       "4                       3.52  \n",
       "5                       4.69  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: llama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>drop</th>\n",
       "      <th>gpqa</th>\n",
       "      <th>hotpotqa</th>\n",
       "      <th>math500</th>\n",
       "      <th>musr_efficiently</th>\n",
       "      <th>musr_location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>26.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.2</td>\n",
       "      <td>14.65</td>\n",
       "      <td>19.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.2</td>\n",
       "      <td>13.64</td>\n",
       "      <td>17.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>21.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.4</td>\n",
       "      <td>18.18</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.2</td>\n",
       "      <td>30.81</td>\n",
       "      <td>16.2</td>\n",
       "      <td>23.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage                                           \\\n",
       "Task                 drop   gpqa hotpotqa math500 musr_efficiently   \n",
       "Extracted User                                                       \n",
       "-1                    0.0   0.00      0.0     0.0             15.6   \n",
       " 1                   57.0  22.73     32.0    38.8             23.6   \n",
       " 2                   16.2  14.65     19.6     8.8             11.6   \n",
       " 3                    6.2  13.64     17.6    14.8              5.6   \n",
       " 4                    8.4  18.18     14.6    13.6             11.6   \n",
       " 5                   12.2  30.81     16.2    23.8             32.0   \n",
       " 10                   0.0   0.00      0.0     0.2              0.0   \n",
       "\n",
       "                              \n",
       "Task           musr_location  \n",
       "Extracted User                \n",
       "-1                      5.08  \n",
       " 1                     26.95  \n",
       " 2                      5.47  \n",
       " 3                     21.88  \n",
       " 4                      1.56  \n",
       " 5                     39.06  \n",
       " 10                     0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_overall = pd.DataFrame(overall_summary)\n",
    "\n",
    "for model in df_overall[\"Model\"].unique():\n",
    "    model_df = df_overall[df_overall[\"Model\"] == model]\n",
    "    \n",
    "    pivot_table = model_df.pivot_table(\n",
    "        index=\"Extracted User\",       \n",
    "        columns=\"Task\",               \n",
    "        values=[\"Percentage\"], \n",
    "        fill_value=0           \n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel: {model}\")\n",
    "    display(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-business: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 56810.29it/s]\n",
      "gpt-4o-mini-law: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 48438.66it/s]\n",
      "gpt-4o-mini-psychology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 57262.73it/s]\n",
      "gpt-4o-mini-biology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 57039.49it/s]\n",
      "gpt-4o-mini-chemistry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 50183.11it/s]\n",
      "gpt-4o-mini-history: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 54346.79it/s]\n",
      "gpt-4o-mini-other: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 57889.73it/s]\n",
      "gpt-4o-mini-health: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 58348.77it/s]\n",
      "gpt-4o-mini-economics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 58208.41it/s]\n",
      "gpt-4o-mini-math: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 57839.17it/s]\n",
      "gpt-4o-mini-physics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 53063.35it/s]\n",
      "gpt-4o-mini-computer science: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 55465.54it/s]\n",
      "gpt-4o-mini-philosophy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 54794.08it/s]\n",
      "gpt-4o-mini-engineering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 47796.52it/s]\n",
      "gpt-4o-business: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 48269.57it/s]\n",
      "gpt-4o-law: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 41378.91it/s]\n",
      "gpt-4o-psychology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 46679.45it/s]\n",
      "gpt-4o-biology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 46510.36it/s]\n",
      "gpt-4o-chemistry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 43717.99it/s]\n",
      "gpt-4o-history: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 45986.81it/s]\n",
      "gpt-4o-other: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 49119.38it/s]\n",
      "gpt-4o-health: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 48136.62it/s]\n",
      "gpt-4o-economics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 46672.52it/s]\n",
      "gpt-4o-math: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 48206.70it/s]\n",
      "gpt-4o-physics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 46291.34it/s]\n",
      "gpt-4o-computer science: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 49683.77it/s]\n",
      "gpt-4o-philosophy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 47213.66it/s]\n",
      "gpt-4o-engineering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 41368.02it/s]\n",
      "llama-business: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 74292.45it/s]\n",
      "llama-law: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 60098.93it/s]\n",
      "llama-psychology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 71162.27it/s]\n",
      "llama-biology: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 71579.23it/s]\n",
      "llama-chemistry: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 80294.25it/s]\n",
      "llama-history: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 68482.16it/s]\n",
      "llama-other: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 74086.86it/s]\n",
      "llama-health: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 68936.13it/s]\n",
      "llama-economics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 71615.89it/s]\n",
      "llama-math: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 76176.97it/s]\n",
      "llama-physics: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 78672.70it/s]\n",
      "llama-computer science: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 70559.70it/s]\n",
      "llama-philosophy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 69011.75it/s]\n",
      "llama-engineering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 72561.63it/s]\n"
     ]
    }
   ],
   "source": [
    "overall_summary_mmlu = []\n",
    "\n",
    "def process_mmlu_pro(model: str):\n",
    "    task = \"mmlu_pro\"\n",
    "\n",
    "    prompting_path = (\n",
    "        f\"{config.output_dir}/{task}/{model}/\"\n",
    "        f\"{task}_{config.shot_type}.jsonl\"\n",
    "    )\n",
    "    all_entries = load_model_outputs(prompting_path)\n",
    "\n",
    "    grouped = defaultdict(list)  \n",
    "\n",
    "    for entry in all_entries:\n",
    "        subj = entry[\"entry\"][\"category\"]          \n",
    "\n",
    "        grouped[subj].append(entry)\n",
    "\n",
    "    if model != 'llama': \n",
    "        for subj in grouped:\n",
    "            grouped[subj].sort(key=lambda e: e[\"idx\"])\n",
    "\n",
    "\n",
    "    for subject, entries in grouped.items():\n",
    "        output_res_path = f\"../result/{task}/{model}/{subject}_result.jsonl\"\n",
    "        res = load_model_outputs(output_res_path)\n",
    "\n",
    "\n",
    "        user_counter = Counter()\n",
    "        total = len(entries)\n",
    "\n",
    "        for idx, llm_prompt in enumerate(\n",
    "            tqdm(entries, desc=f\"{model}-{subject}\")\n",
    "        ):\n",
    "            \n",
    "            raw_output = llm_prompt.get(\"prompt_output\")          \n",
    "            if isinstance(raw_output, list):\n",
    "                p_out = raw_output[0] if raw_output else None\n",
    "            else:\n",
    "                p_out = raw_output                   \n",
    "\n",
    "\n",
    "            if p_out is None:\n",
    "                user_num = None\n",
    "            else:\n",
    "                user_num = extract_user_number(p_out)\n",
    "\n",
    "\n",
    "            key = user_num if user_num is not None else \"None\"\n",
    "            user_counter[key] += 1\n",
    "\n",
    "\n",
    "            if not isinstance(user_num, int) or not (0 <= user_num <= 4):\n",
    "                user_num = 0  # fallback\n",
    "\n",
    "\n",
    "            outs = res[idx].get(\"model_outputs\") or res[idx].get(\"resps\")[0]\n",
    "            chosen = (\n",
    "                outs[user_num - 1] if len(outs) >= user_num\n",
    "                else (outs[0] if outs else None)\n",
    "            )\n",
    "            entries[idx][\"prompt_output_with_fewshot\"] = chosen\n",
    "\n",
    "        dir_path = f\"{config.output_dir}/{task}/{model}/{subject}\"\n",
    "        file_name = f\"{task}_{config.shot_type}.jsonl\"\n",
    "        save_path = os.path.join(dir_path, file_name)\n",
    "\n",
    "\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "        for u, cnt in user_counter.items():\n",
    "            overall_summary_mmlu.append({\n",
    "                \"Model\": model,\n",
    "                \"Task\": task,\n",
    "                \"Subject\": subject,\n",
    "                \"Extracted User\": u,\n",
    "                \"Count\": cnt,\n",
    "                \"Percentage\": round(cnt / total * 100, 2)\n",
    "            })\n",
    "\n",
    "\n",
    "for model in ['gpt-4o-mini', 'gpt-4o', 'llama']:\n",
    "    process_mmlu_pro(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>mmlu_pro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1.563846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.189286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.737857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage\n",
       "Task             mmlu_pro\n",
       "Extracted User           \n",
       "-1               1.563846\n",
       " 1              68.189286\n",
       " 2              12.595000\n",
       " 3               8.310000\n",
       " 4               4.737857\n",
       " 5               4.714286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: gpt-4o\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>mmlu_pro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.667857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.333571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.308571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage\n",
       "Task             mmlu_pro\n",
       "Extracted User           \n",
       "1               82.667857\n",
       "2               10.333571\n",
       "3                3.786429\n",
       "4                1.406667\n",
       "5                2.308571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: llama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>mmlu_pro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extracted User</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1.388333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.452143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.119286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.713571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.451429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.975714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Percentage\n",
       "Task             mmlu_pro\n",
       "Extracted User           \n",
       "-1               1.388333\n",
       " 1              25.452143\n",
       " 2              12.119286\n",
       " 3              14.713571\n",
       " 4              16.451429\n",
       " 5              29.975714\n",
       " 6               0.330000\n",
       " 7               1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mmlu = pd.DataFrame(overall_summary_mmlu)\n",
    "\n",
    "for model in df_mmlu[\"Model\"].unique():\n",
    "    model_df = df_mmlu[df_mmlu[\"Model\"] == model]\n",
    "    \n",
    "    pivot_table = model_df.pivot_table(\n",
    "        index=\"Extracted User\",       \n",
    "        columns=\"Task\",               \n",
    "        values=[\"Percentage\"], \n",
    "        fill_value=0           \n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel: {model}\")\n",
    "    display(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_eval = ['prompt_output_with_fewshot']\n",
    "models = ['gpt-4o-mini', 'gpt-4o', 'llama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation Results for model=gpt-4o-mini, shot=few =====\n",
      "prompt_output_with_fewshot -> Accuracy: 0.7920\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Evaluation Results for model=gpt-4o, shot=few =====\n",
      "prompt_output_with_fewshot -> Accuracy: 0.8080\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Evaluation Results for model=llama, shot=few =====\n",
      "prompt_output_with_fewshot -> Accuracy: 0.4600\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from math500.math_utils import * \n",
    "from math500.parser import *\n",
    "from math500.grader import * \n",
    "\n",
    "for model in models:\n",
    "    file_path = f\"{config.output_dir}/math500/{model}/math500_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "\n",
    "    scores = {k: [] for k in keys_to_eval}\n",
    "\n",
    "    for entry in data:\n",
    "        idx = entry[\"idx\"]\n",
    "        \n",
    "        _, gt = parse_ground_truth(entry['entry'], \"math\")\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        \n",
    "        for key in keys_to_eval:\n",
    "            if key not in entry:\n",
    "                continue\n",
    "\n",
    "\n",
    "            pred = extract_answer(entry[key], \"math\")\n",
    "            pred = strip_string(pred)\n",
    "\n",
    "\n",
    "            try:\n",
    "                result = math_equal_process((idx, pred, gt))\n",
    "\n",
    "                if not result :\n",
    "                    result = process_results(gt, [entry[key]])\n",
    "                    if not result:\n",
    "                        pred = extract_answer(pred, \"math\")\n",
    "                        result = math_equal_process((None, pred, gt))\n",
    "\n",
    "                scores[key].append(result)\n",
    "\n",
    "            except TimeoutError:\n",
    "                scores[key].append(False)\n",
    "            except Exception as error:\n",
    "                print(f\"Error while processing {key} for idx={idx}: {error}\")\n",
    "                scores[key].append(False)\n",
    "\n",
    "    print(f\"\\n===== Evaluation Results for model={model}, shot={config.shot_type} =====\")\n",
    "    for key in keys_to_eval:\n",
    "        if len(scores[key]) == 0:\n",
    "            print(f\"{key} -> No data / Not found in entries\")\n",
    "            continue\n",
    "\n",
    "        acc = sum(scores[key]) / len(scores[key])\n",
    "        print(f\"{key} -> Accuracy: {acc:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Results for model=gpt-4o-mini ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.6479\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Overall Results for model=gpt-4o ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.7657\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Overall Results for model=llama ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.4407\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def extract_answer(text):\n",
    "    pattern = r\"answer is \\(?([A-J])\\)?\"\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return extract_again(text)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    overall_scores = {k: 0 for k in keys_to_eval}  \n",
    "    overall_total_entries = 0\n",
    "\n",
    "    for subject in subjects:\n",
    "        file_path = f\"{config.output_dir}/mmlu_pro/{model}/{subject}/mmlu_pro_few.jsonl\"\n",
    "        data = load_model_outputs(file_path)\n",
    "\n",
    "\n",
    "        subject_scores = {k: 0 for k in keys_to_eval}\n",
    "        total_data_len = len(data)\n",
    "        overall_total_entries += total_data_len\n",
    "\n",
    "        for entry in data:\n",
    "            model_outputs = entry.get('model_outputs', [])\n",
    "            answer = entry['entry'].get('answer') or entry['entry'].get('gold')\n",
    "\n",
    "\n",
    "            for key in keys_to_eval:\n",
    "                if key not in entry:\n",
    "                    continue\n",
    "                pred = extract_answer(entry[key])\n",
    "                if pred == answer: \n",
    "                    subject_scores[key] += 1\n",
    "\n",
    "\n",
    "        for k in keys_to_eval:\n",
    "            overall_scores[k] += subject_scores[k]\n",
    "\n",
    "           \n",
    "    print(f\"\\n=== Overall Results for model={model} ===\")\n",
    "    for key in keys_to_eval:\n",
    "        if overall_total_entries == 0:\n",
    "            acc = 0\n",
    "        else:\n",
    "            acc = overall_scores[key] / overall_total_entries\n",
    "        print(f\"{key} -> Accuracy: {acc:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results for model=gpt-4o-mini, shot=few ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.3990\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Results for model=gpt-4o, shot=few ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.5101\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Results for model=llama, shot=few ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.2121\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from gpqa.gpqa_utils import * \n",
    "\n",
    "examples = load_examples(\"../data/gpqa/gpqa_diamond.csv\", seed=0)\n",
    "\n",
    "for model in models:\n",
    "    file_path = f\"{config.output_dir}/gpqa/{model}/gpqa_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "\n",
    "    scores = {k: 0 for k in keys_to_eval}\n",
    "\n",
    "\n",
    "    total_data_len = len(data)\n",
    "    if total_data_len != len(examples):\n",
    "        print(\"Warning: data length and examples length do not match!\")\n",
    "\n",
    "    \n",
    "    \n",
    "    for entry, example in zip(data, examples):\n",
    "        correct_index = example.correct_index  \n",
    "\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        \n",
    "        for key in keys_to_eval:\n",
    "            if key not in entry:\n",
    "                continue\n",
    "\n",
    "            pred = parse_sampled_answer(entry[key])\n",
    "            \n",
    "            if pred is None:\n",
    "                is_correct = False\n",
    "            else:\n",
    "                is_correct = (LETTER_TO_INDEX[pred] == correct_index)\n",
    "\n",
    "            scores[key] += int(is_correct)\n",
    "    \n",
    "    print(f\"\\n=== Results for model={model}, shot={config.shot_type} ===\")\n",
    "    for key in keys_to_eval:\n",
    "        acc = scores[key] / total_data_len if total_data_len else 0\n",
    "        print(f\"{key} -> Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "\n",
      "===== Results for model=gpt-4o-mini =====\n",
      "prompt_output_with_fewshot -> EM: 0.7860, F1: 0.8563\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "\n",
      "===== Results for model=gpt-4o =====\n",
      "prompt_output_with_fewshot -> EM: 0.8240, F1: 0.9017\n",
      "--------------------------------------------------\n",
      "llama\n",
      "\n",
      "===== Results for model=llama =====\n",
      "prompt_output_with_fewshot -> EM: 0.6760, F1: 0.7402\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from drop.drop_utils import *\n",
    "\n",
    "for model in models: \n",
    "    print(model)\n",
    "    entry_path = f\"{config.output_dir}/drop/gpt-4o/drop_{config.shot_type}.jsonl\"\n",
    "    entry_data = load_model_outputs(entry_path)\n",
    "\n",
    "    file_path = f\"{config.output_dir}/drop/{model}/drop_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "    \n",
    "    em_scores = {k: [] for k in keys_to_eval}\n",
    "    f1_scores = {k: [] for k in keys_to_eval}\n",
    "\n",
    "    def get_max_em_f1(pred, golds):\n",
    "        max_em, max_f1 = 0.0, 0.0\n",
    "        for gold_answer in golds:\n",
    "            exact_match, f1_score = get_metrics(pred, gold_answer)\n",
    "            if gold_answer[0].strip():\n",
    "                max_em = max(max_em, exact_match)\n",
    "                max_f1 = max(max_f1, f1_score)\n",
    "        return max_em, max_f1\n",
    "\n",
    "    for test_idx, entry in enumerate(data):\n",
    "        golds = get_answers(entry_data[test_idx]['entry']) \n",
    "\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        \n",
    "        for k in keys_to_eval:\n",
    "            if k not in entry:\n",
    "                continue\n",
    "\n",
    "            pred = extract_answer(entry[k])\n",
    "            em_val, f1_val = get_max_em_f1(pred, golds)\n",
    "            em_scores[k].append(em_val)\n",
    "            f1_scores[k].append(f1_val)\n",
    "\n",
    "    print(f\"\\n===== Results for model={model} =====\")\n",
    "    for k in keys_to_eval:\n",
    "        if len(em_scores[k]) == 0:\n",
    "            print(f\"{k}: No entries found, skip.\")\n",
    "            continue\n",
    "\n",
    "        em_mean = np.mean(em_scores[k])\n",
    "        f1_mean = np.mean(f1_scores[k])\n",
    "        print(f\"{k} -> EM: {em_mean:.4f}, F1: {f1_mean:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "\n",
      "=== Results for model=gpt-4o-mini ===\n",
      "prompt_output_with_fewshot -> EM: 0.3620, F1: 0.4836\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "\n",
      "=== Results for model=gpt-4o ===\n",
      "prompt_output_with_fewshot -> EM: 0.4660, F1: 0.6134\n",
      "--------------------------------------------------\n",
      "llama\n",
      "\n",
      "=== Results for model=llama ===\n",
      "prompt_output_with_fewshot -> EM: 0.2340, F1: 0.3121\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from hotpotqa.hotpotqa_utils import *\n",
    "\n",
    "def extract_answer(response_text):\n",
    "    match = re.search(r\"Answer\\s+(.+)\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "\n",
    "        answer = re.sub(r\"[.\\n]+$\", \"\", answer).strip()\n",
    "        return answer\n",
    "\n",
    "\n",
    "    match = re.search(r\"(?<!\\w)Answer[:\\s]+(.+?)(?:[.\\n]|$)\", response_text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "\n",
    "        answer = re.sub(r\"[.\\n]+$\", \"\", answer).strip()\n",
    "        return answer\n",
    "    return response_text.strip()\n",
    "\n",
    "\n",
    "dataset = json.load(open(f'../data/hotpotqa/BM25/hotpotqa-bm25.json'))\n",
    "with open(\"../hotpotqa/react_prompt.json\", 'r') as f:\n",
    "    fewshot = json.load(f)\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    file_path = f\"{config.output_dir}/hotpotqa/{model}/hotpotqa_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "    preds = {k: [] for k in keys_to_eval}\n",
    "\n",
    "    for entry in data:\n",
    "\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        \n",
    "        for k in keys_to_eval:\n",
    "            if k in entry:\n",
    "\n",
    "                answer = extract_answer(entry[k])\n",
    "                preds[k].append(answer)\n",
    "\n",
    "    print(f\"\\n=== Results for model={model} ===\")\n",
    "    for k in keys_to_eval:\n",
    "        if len(preds[k]) == 0:\n",
    "            print(f\"{k}: No entries found, skip.\")\n",
    "            continue\n",
    "\n",
    "        em_scores, f1_scores = get_em_f1(dataset, preds[k])\n",
    "        em_mean = em_scores.mean()\n",
    "        f1_mean = f1_scores.mean()\n",
    "        print(f\"{k} -> EM: {em_mean:.4f}, F1: {f1_mean:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from musr.musr import MuSRDataset\n",
    "\n",
    "ta_path = '../data/musr/team_allocation.json'\n",
    "ta = MuSRDataset(ta_path)\n",
    "\n",
    "op_path = '../data/musr/object_placements.json'\n",
    "op = MuSRDataset(op_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "\n",
      "=== Results for model=gpt-4o-mini ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.5859\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "\n",
      "=== Results for model=gpt-4o ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.7227\n",
      "--------------------------------------------------\n",
      "llama\n",
      "\n",
      "=== Results for model=llama ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.5508\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "    file_path = f\"{config.output_dir}/musr_location/{model}/musr_location_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "    \n",
    "    \n",
    "    preds = {k: [] for k in keys_to_eval}\n",
    "\n",
    "\n",
    "    for test_idx, entry in enumerate(data):\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        for k in keys_to_eval:\n",
    "            if k in entry:  \n",
    "                preds[k].append(entry[k])\n",
    "            else:\n",
    "                preds[k].append(None)\n",
    "\n",
    "    total_data_len = len(data)\n",
    "    \n",
    "    scores = {k: 0 for k in keys_to_eval}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        if 'entry' not in entry:\n",
    "            continue\n",
    "        \n",
    "        for k in keys_to_eval:\n",
    "            pred_answer = preds[k][i]\n",
    "            if pred_answer is not None:\n",
    "                metrics = op.evaluate_response([pred_answer], op[i])\n",
    "                if metrics and metrics[0]['correct']:\n",
    "                    scores[k] += 1\n",
    "\n",
    "\n",
    "    print(f\"\\n=== Results for model={model} ===\")\n",
    "    for k in keys_to_eval:\n",
    "        if len(preds[k]) == 0:\n",
    "            print(f\"{k}: No entries found, skip.\")\n",
    "            continue\n",
    "\n",
    "        acc = scores[k] / total_data_len if total_data_len else 0\n",
    "        print(f\"{k} -> Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "\n",
      "=== Results for model=gpt-4o-mini ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.7720\n",
      "--------------------------------------------------\n",
      "gpt-4o\n",
      "\n",
      "=== Results for model=gpt-4o ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.8920\n",
      "--------------------------------------------------\n",
      "llama\n",
      "\n",
      "=== Results for model=llama ===\n",
      "prompt_output_with_fewshot -> Accuracy: 0.6640\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "    file_path = f\"{config.output_dir}/musr_efficiently/{model}/musr_efficiently_{config.shot_type}.jsonl\"\n",
    "    data = load_model_outputs(file_path)\n",
    "    \n",
    "    \n",
    "    preds = {k: [] for k in keys_to_eval}\n",
    "\n",
    "    for test_idx, entry in enumerate(data):\n",
    "        model_outputs = entry.get('model_outputs', [])\n",
    "        for k in keys_to_eval:\n",
    "            if k in entry:  \n",
    "                preds[k].append(entry[k])\n",
    "            else:\n",
    "                preds[k].append(None)\n",
    "\n",
    "    total_data_len = len(data)\n",
    "    \n",
    "    scores = {k: 0 for k in keys_to_eval}\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        if 'entry' not in entry:\n",
    "            continue\n",
    "        \n",
    "        for k in keys_to_eval:\n",
    "            pred_answer = preds[k][i]\n",
    "            if pred_answer is not None:\n",
    "                metrics = ta.evaluate_response([pred_answer], ta[i])\n",
    "                if metrics and metrics[0]['correct']:\n",
    "                    scores[k] += 1\n",
    "\n",
    "    print(f\"\\n=== Results for model={model} ===\")\n",
    "    for k in keys_to_eval:\n",
    "        if len(preds[k]) == 0:\n",
    "            print(f\"{k}: No entries found, skip.\")\n",
    "            continue\n",
    "\n",
    "        acc = scores[k] / total_data_len if total_data_len else 0\n",
    "        print(f\"{k} -> Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
