{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehdtjr1220/miniconda3/envs/proj2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from musr import MuSRDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')  \n",
    "\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_path = '../data/musr/murder_mystery.json'\n",
    "mm = MuSRDataset(mm_path)\n",
    "\n",
    "ta_path = '../data/musr/team_allocation.json'\n",
    "ta = MuSRDataset(ta_path)\n",
    "\n",
    "op_path = '../data/musr/object_placements.json'\n",
    "op = MuSRDataset(op_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team allocation\n",
      "gpt-4o-mini 79.6\n",
      "gpt-4o 89.6\n",
      "Object Placements\n",
      "gpt-4o-mini 62.1\n",
      "gpt-4o 73.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Team allocation\")\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']: \n",
    "    file_path = f\"../result/musr_efficiently/{model}/musr_efficiently_few_greedy.jsonl\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "    idx_acc = [0]\n",
    "    for entry in data: \n",
    "        model_outputs = entry['model_outputs']\n",
    "        for idx, model_output in enumerate(model_outputs): \n",
    "            metrics = ta.evaluate_response([model_output], entry['entry'])\n",
    "            idx_acc[idx] += metrics[0]['correct']\n",
    "    total = 0 \n",
    "    for ac in idx_acc: \n",
    "        total += ac / len(data)\n",
    "    \n",
    "    total = total * 100 \n",
    "    print(f\"{model} {total:.1f}\")\n",
    "        \n",
    "print(\"Object Placements\")\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']: \n",
    "    file_path = f\"../result/musr_location/{model}/musr_location_few_greedy.jsonl\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "    idx_acc = [0]\n",
    "    for entry in data: \n",
    "        model_outputs = entry['model_outputs']\n",
    "        for idx, model_output in enumerate(model_outputs): \n",
    "            metrics = op.evaluate_response([model_output], entry['entry'])\n",
    "            idx_acc[idx] += metrics[0]['correct']\n",
    "    total = 0 \n",
    "    for ac in idx_acc: \n",
    "        total += ac / len(data)\n",
    "        \n",
    "    total = total * 100 \n",
    "    print(f\"{model} {total:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team allocation\n",
      "gpt-4o-mini zero 0.5624\n",
      "gpt-4o-mini few 0.7696\n",
      "gpt-4o zero 0.6664\n",
      "gpt-4o few 0.8696\n",
      "Object Placements\n",
      "gpt-4o-mini zero 0.5813\n",
      "gpt-4o-mini few 0.5938\n",
      "gpt-4o zero 0.6172\n",
      "gpt-4o few 0.6969\n"
     ]
    }
   ],
   "source": [
    "print(\"Team allocation\")\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']: \n",
    "    for shot_type in ['zero', 'few']:\n",
    "        file_path = f\"../result_gpt/musr_efficiently/{model}/musr_efficiently_{shot_type}.jsonl\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = [json.loads(line) for line in f]\n",
    "        idx_acc = [0,0,0,0,0]\n",
    "        for entry in data: \n",
    "            model_outputs = entry['model_outputs']\n",
    "            for idx, model_output in enumerate(model_outputs): \n",
    "                metrics = ta.evaluate_response([model_output], entry['entry'])\n",
    "                idx_acc[idx] += metrics[0]['correct']\n",
    "        total = 0 \n",
    "        for ac in idx_acc: \n",
    "            total += ac / len(data)\n",
    "\n",
    "        print(f\"{model} {shot_type} {total / 5:.4f}\")\n",
    "        \n",
    "print(\"Object Placements\")\n",
    "for model in ['gpt-4o-mini', 'gpt-4o']: \n",
    "    for shot_type in ['zero', 'few']:\n",
    "        file_path = f\"../result_gpt/musr_location/{model}/musr_location_{shot_type}.jsonl\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = [json.loads(line) for line in f]\n",
    "        idx_acc = [0,0,0,0,0]\n",
    "        for entry in data: \n",
    "            model_outputs = entry['model_outputs']\n",
    "            for idx, model_output in enumerate(model_outputs): \n",
    "                metrics = op.evaluate_response([model_output], entry['entry'])\n",
    "                idx_acc[idx] += metrics[0]['correct']\n",
    "        total = 0 \n",
    "        for ac in idx_acc: \n",
    "            total += ac / len(data)\n",
    "\n",
    "        print(f\"{model} {shot_type} {total / 5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team allocation\n",
      "llama zero 0.4304\n",
      "llama few 0.6480\n",
      "Object Placements\n",
      "llama zero 0.5062\n",
      "llama few 0.5328\n"
     ]
    }
   ],
   "source": [
    "print(\"Team allocation\")\n",
    "for model in ['llama']: \n",
    "    for shot_type in ['zero', 'few']:\n",
    "        file_path = f\"../result/musr_efficiently/llama/musr_efficiently_{shot_type}.jsonl\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = [json.loads(line) for line in f]\n",
    "        idx_acc = [0,0,0,0,0]\n",
    "        for test_idx, entry in enumerate(data): \n",
    "            model_outputs = entry['resps'][0]\n",
    "            for idx, model_output in enumerate(model_outputs): \n",
    "                metrics = ta.evaluate_response([model_output], ta[test_idx])\n",
    "                idx_acc[idx] += metrics[0]['correct']\n",
    "        total = 0 \n",
    "        for ac in idx_acc: \n",
    "            total += ac / len(data)\n",
    "\n",
    "        print(f\"{model} {shot_type} {total / 5:.4f}\")\n",
    "\n",
    "print(\"Object Placements\")\n",
    "for model in ['llama']: \n",
    "    for shot_type in ['zero', 'few']:\n",
    "        file_path = f\"../result/musr_location/llama/musr_location_{shot_type}.jsonl\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = [json.loads(line) for line in f]\n",
    "        idx_acc = [0,0,0,0,0]\n",
    "        for test_idx, entry in enumerate(data): \n",
    "            model_outputs = entry['resps'][0]\n",
    "            for idx, model_output in enumerate(model_outputs): \n",
    "                metrics = op.evaluate_response([model_output], op[test_idx])\n",
    "                idx_acc[idx] += metrics[0]['correct']\n",
    "        total = 0 \n",
    "        for ac in idx_acc: \n",
    "            total += ac / len(data)\n",
    "\n",
    "        print(f\"{model} {shot_type} {total / 5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_likelihoods_with_is_correct(file_path, test_data, eval_func):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: JSON file not found at {file_path}\")\n",
    "        return\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    problem_groups = list(zip(*json_data))\n",
    "    \n",
    "    for problem_likelihoods in tqdm(problem_groups, desc=\"Updating likelihoods\"):\n",
    "        problem_list = list(problem_likelihoods)\n",
    "\n",
    "        idx = problem_list[0].get(\"id\")\n",
    "        if idx is None or idx >= len(test_data):\n",
    "            print(f\"Warning: Invalid or missing id in candidate: {problem_list[0]}\")\n",
    "            continue\n",
    "\n",
    "        test_entry = test_data[idx]\n",
    "        for cl in problem_list:\n",
    "            metrics = eval_func([cl['model_output']], test_entry)\n",
    "            cl['is_correct'] = metrics[0]['correct']\n",
    "    \n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Updated predictions saved at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 250/250 [00:00<00:00, 10981.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_efficiently//gpt-4o-mini/few/all_likelihoods.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 250/250 [00:00<00:00, 11217.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_efficiently//gpt-4o/few/all_likelihoods.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 250/250 [00:00<00:00, 306.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_efficiently//llama/few/all_likelihoods.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 10270.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_location//gpt-4o-mini/few/all_likelihoods.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 14643.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_location//gpt-4o/few/all_likelihoods.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 1071.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved at: ../likelihood_1B/musr_location//llama/few/all_likelihoods.json\n"
     ]
    }
   ],
   "source": [
    "models = ['gpt-4o-mini', 'gpt-4o', 'llama']\n",
    "# models = ['llama']\n",
    "file_name = 'few/all_likelihoods.json'\n",
    "\n",
    "output_dir = \"../likelihood_1B/musr_efficiently/\"\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for shot_type in ['few']:\n",
    "        file_path = f\"{output_dir}/{model}/{file_name}\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        update_likelihoods_with_is_correct(file_path, ta, ta.evaluate_response)\n",
    "\n",
    "output_dir = \"../likelihood_1B/musr_location/\"\n",
    "\n",
    "for model in models:\n",
    "    for shot_type in ['few']:\n",
    "        file_path = f\"{output_dir}/{model}/{file_name}\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        update_likelihoods_with_is_correct(file_path, op, op.evaluate_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 257060.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6015625\n",
      "0.6015625\n",
      "0.55078125\n",
      "0.58984375\n",
      "0.625\n",
      "0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 165064.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n",
      "0.70703125\n",
      "0.67578125\n",
      "0.69921875\n",
      "0.68359375\n",
      "0.696875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating likelihoods: 100%|██████████| 256/256 [00:00<00:00, 160715.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51171875\n",
      "0.46875\n",
      "0.49609375\n",
      "0.53515625\n",
      "0.515625\n",
      "0.50546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../likelihood/musr_location/\"\n",
    "file_name = 'few/all_likelihoods.json'\n",
    "\n",
    "\n",
    "for model in ['gpt-4o-mini', 'gpt-4o', 'llama']:\n",
    "    for shot_type in ['few']:\n",
    "        file_path = f\"{output_dir}/{model}/{file_name}\"\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        problem_groups = list(zip(*json_data))\n",
    "        \n",
    "        idx_acc = [0,0,0,0,0]\n",
    "        for problem_likelihoods in tqdm(problem_groups, desc=\"Updating likelihoods\"):\n",
    "            problem_list = list(problem_likelihoods)\n",
    "\n",
    "            for idx, cl in enumerate(problem_list):\n",
    "                idx_acc[idx] += cl['is_correct'] \n",
    "        \n",
    "        total = 0 \n",
    "        for ac in idx_acc:\n",
    "            acc = ac / len(problem_groups) \n",
    "            total += acc\n",
    "            print(acc)\n",
    "        print(total / 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
